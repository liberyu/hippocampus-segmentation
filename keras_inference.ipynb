{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "\n",
    "def squeeze_dim(img):\n",
    "    if img.ndim == 4: \n",
    "        if img.shape[0] == 1:\n",
    "            img = np.squeeze(img,axis=0)\n",
    "        if img.shape[1] == 1:\n",
    "            img = np.squeeze(img,axis=1)\n",
    "        if img.shape[2] == 1:\n",
    "            img = np.squeeze(img,axis=2)\n",
    "        if img.shape[3] == 1:\n",
    "            img = np.squeeze(img,axis=3)\n",
    "    else:\n",
    "        pass\n",
    "    return img\n",
    "def crop(img, a , b, c):\n",
    "    '''\n",
    "    有一个缺点就是 a,b,c的值只能是偶数,即便是设置为奇数,返回的shape也是(a-1,b-1,c-1)之类的偶数形状\n",
    "    '''\n",
    "    img_shape = img.shape\n",
    "    img_a = img_shape[0]\n",
    "    img_b = img_shape[1]\n",
    "    img_c = img_shape[2]\n",
    "    img_res = img[img_a/2-a/2:img_a/2+a/2, img_b/2-b/2:img_b/2+b/2, img_c/2-c/2:img_c/2+c/2]\n",
    "    return img_res\n",
    "def decrop(in_img,shell):\n",
    "    \"\"\"\n",
    "    shell 是一个全零的壳子矩阵,用来装预测的图形\n",
    "    in_img 是预测得到的被剪切图像\n",
    "    \"\"\"\n",
    "    in_img_shape = in_img.shape\n",
    "    shell_shape = shell.shape\n",
    "    a = in_img_shape[0]\n",
    "    b = in_img_shape[1]\n",
    "    c = in_img_shape[2]\n",
    "    img_a = shell_shape[0]\n",
    "    img_b = shell_shape[1]\n",
    "    img_c = shell_shape[2]\n",
    "    shell[img_a/2-a/2:img_a/2+a/2, img_b/2-b/2:img_b/2+b/2, img_c/2-c/2:img_c/2+c/2] = in_img\n",
    "    return shell\n",
    "def make_csv(floder= 'sample/image',save_name='./test.csv'):\n",
    "    \"\"\"\n",
    "    get all filename in floder to make a csv_file\n",
    "    input:\n",
    "        floder is a path(type = string)\n",
    "    \"\"\"\n",
    "    list_file = os.listdir(floder)\n",
    "    csvfile = file(save_name,'wb')\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['path'])\n",
    "    list_file.sort()\n",
    "    for file_name in list_file:\n",
    "        writer.writerow([file_name])\n",
    "    csvfile.close()\n",
    "def loadDataGeneral(df,target_floder, append_coord):\n",
    "    \"\"\"\n",
    "    这个是将待测图片整体读入,然后记录shape 其中做了整体的归一化\n",
    "    This function loads data stored in nifti format. Data should already be of\n",
    "    appropriate shape.\n",
    "\n",
    "    Inputs:\n",
    "    - df: Pandas dataframe with two columns: image filenames and ground truth filenames.\n",
    "    - path: Path to folder containing filenames from df.\n",
    "    - append_coords: Whether to append coordinate channels or not.\n",
    "    Returns:\n",
    "    - X: Array of 3D images with 1 or 4 channels depending on `append_coords`.\n",
    "    - y: Array of 3D masks with 1 channel.\n",
    "    \"\"\"\n",
    "   \n",
    "    X, shape_list = [], []\n",
    "    for i, item in df.iterrows():\n",
    "\n",
    "        img_path = ''.join([str(target_floder), item[0]])\n",
    "\n",
    "        nii_img = nib.load(img_path)\n",
    "        img = nii_img.get_data()\n",
    "        shape = img.shape\n",
    "        img = squeeze_dim(img)\n",
    "        img = crop(img,96,96,80)\n",
    "\n",
    "        img = np.array(img, dtype=np.float64)\n",
    "        img -= img.mean()\n",
    "        img /= img.std()\n",
    "        X.append(img)\n",
    "        shape_list.append(shape)\n",
    "\n",
    "    X = np.array(X)\n",
    "    X -= X.mean()    #如果不做整体的归一化,则注释这两句\n",
    "    X /= X.std()\n",
    "    X = np.expand_dims(X, -1)  # X.shape  --> (4,128,128,64,1)\n",
    "    \n",
    "    # Option to append coordinates as additional channels\n",
    "    if append_coord:\n",
    "        n = X.shape[0]\n",
    "        inpShape = X.shape[1:]\n",
    "        xx = np.empty(inpShape)\n",
    "        for i in xrange(inpShape[1]):\n",
    "            xx[:, i, :, 0] = i\n",
    "        yy = np.empty(inpShape)\n",
    "        for i in xrange(inpShape[0]):\n",
    "            yy[i, :, :, 0] = i\n",
    "        zz = np.empty(inpShape)\n",
    "        for i in xrange(inpShape[2]):\n",
    "            zz[:, :, i, 0] = i\n",
    "        X = np.concatenate([X, np.array([xx] * n), np.array([yy] * n), np.array([zz] * n)], -1)\n",
    "\n",
    "    print '### Dataset loaded'\n",
    "    print '\\t{}'.format(target_floder)\n",
    "    print '\\t{}\\t'.format(X.shape)\n",
    "    print '\\tX:{:.1f}-{:.1f}\\t'.format(X.min(), X.max())\n",
    "    return X, shape_list\n",
    "def prediction(csv_path, target_floder,append_coords = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    载入的模型名称是my_model.hdf5\n",
    "    用以针对一个文件夹下边的文件进行整体的预测,并保存预测图像到与target_floder文件夹相同子目录pred文件夹下\n",
    "    这个做的对原图(未经过裁剪的图像)进行的推断,得到的是与原图相匹配的pred文件\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path) \n",
    "    X,shape_list= loadDataGeneral(df,target_floder, append_coords)\n",
    "    n_test = X.shape[0]   \n",
    "    model_name = 'my_model.hdf5' # Model should be trained with the same `append_coords`\n",
    "    model = load_model(model_name)\n",
    "    pred = model.predict(X, batch_size=1)[..., 1]  \n",
    "    save_pred_floder = target_floder[:target_floder.rfind(\"/\")]+'/pred/'\n",
    "    if not os.path.exists(save_pred_floder):\n",
    "        os.makedirs(save_pred_floder)\n",
    "    for i in range(n_test):\n",
    "\n",
    "        pr = pred[i] > 0.5 # binary prediction\n",
    "        shell = np.zeros(shape_list[i])\n",
    "        pr = decrop(pr,shell)\n",
    "\n",
    "        tImg = nib.load(target_floder + df.ix[i].path)\n",
    "        nib.save(nib.Nifti1Image(255 * pr.astype('float'), affine=tImg.get_affine()),\n",
    "                 save_pred_floder + df.ix[i].path[:-7]+'-pred.nii.gz')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = 'new_rotate/test.csv'\n",
    "    target_floder = '/home/yanyu/competition/new_rotate/test_data'\n",
    "    prediction(csv_path,target_floder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#这个文件是用来对生成的pred文件和gt两个文件夹中的图像进行求dice值和iou\n",
    "#\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import csv\n",
    "\"\"\"\n",
    "比较上个文件生成的pred和gt,对比dice和iou\n",
    "\"\"\"\n",
    "def make_csv(floder= 'sample/image',save_name='test.csv'):\n",
    "    \"\"\"\n",
    "    get all filename in floder to make a csv_file\n",
    "    input:\n",
    "        floder is a path(type = string)\n",
    "    \"\"\"\n",
    "    list_file = os.listdir(floder)\n",
    "    csvfile = file(save_name,'wb')\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['path'])\n",
    "    list_file.sort()\n",
    "    for file_name in list_file:\n",
    "        writer.writerow([file_name])\n",
    "    csvfile.close()\n",
    "\n",
    "def IoU(y_true, y_pred):\n",
    "    assert y_true.dtype == bool and y_pred.dtype == bool\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.logical_and(y_true_f, y_pred_f).sum()\n",
    "    union = np.logical_or(y_true_f, y_pred_f).sum()\n",
    "    return (intersection + 1) * 1. / (union + 1)\n",
    "\n",
    "def Dice(y_true, y_pred):\n",
    "    assert y_true.dtype == bool and y_pred.dtype == bool\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.logical_and(y_true_f, y_pred_f).sum()\n",
    "    return (2. * intersection + 1.) / (y_true.sum() + y_pred.sum() + 1.)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gt_floder = \"path/to/ground/truth/\"\n",
    "    pr_floder = \"path/to/prediction/file/\"  #注意最后的/\n",
    "    make_csv(gt_floder,\"gt.csv\")\n",
    "    make_csv(pr_floder,'pr.csv')\n",
    "    df1 = pd.read_csv(\"gt.csv\")\n",
    "    df2 = pd.read_csv('pr.csv')\n",
    "    IOU = []\n",
    "    DICE = []\n",
    "    for [i,item1],[j,item2] in zip(df1.iterrows(),df2.iterrows()):\n",
    "        gt = nib.load(gt_floder+item1[0]).get_data().astype(np.bool)\n",
    "        pr = nib.load(pr_floder+item2[0]).get_data().astype(np.bool)\n",
    "        iou = IoU(gt,pr)\n",
    "        dice = Dice(gt,pr)\n",
    "        print(\"The number of {}\".format(i))\n",
    "        print(\"iou:{:.5f}\\t dice:{:.5f}\".format(iou,dice))\n",
    "        IOU.append(iou)\n",
    "        DICE.append(dice)\n",
    "    print(\"mean iou is:\")\n",
    "    print(np.array(IOU).mean())\n",
    "    print(\"mean dice is:\")\n",
    "    print(np.array(DICE).mean())\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "i:0\t item1:ADNI_002_S_1018_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070217030439623_S23128_I40817resizecrop.nii.gz\t item2:t1.nii.gz\n",
      "i:1\t item1:ADNI_003_S_0907_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20070501171753634_S19728_I52781resizecrop.nii.gz\t item2:t2.nii.gz\n",
      "i:2\t item1:ADNI_003_S_0981_MR_MPR-R__GradWarp__B1_Correction__N3__Scaled_Br_20070501171453195_S20753_I52776resizecrop.nii.gz\t item2:t3.nii.gz\n",
      "i:3\t item1:ADNI_005_S_0448_MR_MPR__GradWarp__B1_Correction__N3__Scaled_Br_20061212165540546_S14032_I32875resizecrop.nii.gz\t item2:t4.nii.gz\n"
     ]
    }
   ],
   "source": [
    "make_csv('../Demo/crop/image','../Demo/crop/test1.csv')\n",
    "make_csv('../Demo/crop/temp','../Demo/crop/test2.csv')\n",
    "print(\"done\")\n",
    "df1 = pd.read_csv('../Demo/crop/test1.csv')\n",
    "df2 = pd.read_csv('../Demo/crop/test2.csv')\n",
    "for [i,item1],[j,item2] in zip(df1.iterrows(),df2.iterrows()):\n",
    "    print(\"i:{}\\t item1:{}\\t item2:{}\".format(i,item1[0],item2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "a=[1,2,3,4]\n",
    "print(a)\n",
    "b = np.array(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
